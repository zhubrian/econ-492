{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import numpy.linalg as la\n",
    "import pandas as pd\n",
    "import scipy.stats as st\n",
    "import statsmodels.api as sm\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "### SET PARAMETERS ###\n",
    "\n",
    "# set start date\n",
    "start = 8\n",
    "\n",
    "# set holding period\n",
    "H = 7\n",
    "\n",
    "# set lag for momentum \n",
    "L = 7\n",
    "\n",
    "# set number of quantiles\n",
    "Q = 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "### READ IN DATA ###\n",
    "\n",
    "stop = 730\n",
    "\n",
    "rfrate_df = pd.read_csv(r\"C:\\Users\\zhubr\\OneDrive\\Desktop\\ECON 492\\data\\old-i\\rfrate.csv\")\n",
    "rfrate = rfrate_df.iloc[:stop,1].to_numpy()\n",
    "\n",
    "prices_df = pd.read_csv(r\"C:\\Users\\zhubr\\OneDrive\\Desktop\\ECON 492\\data\\old-i\\prices.csv\")\n",
    "prices = prices_df.iloc[:stop,1:].to_numpy()\n",
    "\n",
    "volume_df = pd.read_csv(r\"C:\\Users\\zhubr\\OneDrive\\Desktop\\ECON 492\\data\\old-i\\volume.csv\")\n",
    "volume = volume_df.iloc[:stop,1:].to_numpy()\n",
    "\n",
    "mktcap_df = pd.read_csv(r\"C:\\Users\\zhubr\\OneDrive\\Desktop\\ECON 492\\data\\old-i\\mktcap.csv\")\n",
    "mktcap = mktcap_df.iloc[:stop,1:].to_numpy()\n",
    "\n",
    "T = prices.shape[0]\n",
    "N = prices.shape[1]\n",
    "        \n",
    "### COMPUTE RETURNS ###\n",
    "\n",
    "# get risk-free rate\n",
    "r_f = rfrate[start:]\n",
    "\n",
    "# get returns\n",
    "returns = np.zeros((T-start,N))\n",
    "for t in range(start,T):\n",
    "    for i in range(N):\n",
    "        returns[t-start,i] = 100*(prices[t,i]/prices[t-1,i]-1)\n",
    "        \n",
    "### COMPUTE FACTORS ###\n",
    "        \n",
    "# get size\n",
    "size = mktcap[start:,:]\n",
    "size_0 = mktcap[start-1,:]\n",
    "np.savez(r\"C:\\Users\\zhubr\\OneDrive\\Desktop\\ECON 492\\data\\old-i\\size.npz\",data=size)\n",
    "\n",
    "# get value\n",
    "value = np.zeros((T-start,N))\n",
    "for t in range(start,T):\n",
    "    for i in range(N):\n",
    "        if volume[t,i] == 0:\n",
    "            value[t-start,i] = value[t-start-1,i]\n",
    "        else:\n",
    "            value[t-start,i] = mktcap[t,i]/volume[t,i]\n",
    "        \n",
    "value_0 = np.zeros(N)\n",
    "for i in range(N):\n",
    "    value_0[i] = mktcap[start-1,i]/volume[start-1,i]\n",
    "        \n",
    "# get momentum\n",
    "momentum = np.zeros((T-start,N))\n",
    "for t in range(start,T):\n",
    "    for i in range(N):\n",
    "        prior_returns = np.zeros(L)\n",
    "        for l in range(L):\n",
    "            prior_returns[l] = 100*(prices[t-l,i]/prices[t-l-1,i]-1)\n",
    "        momentum[t-start,i] = np.mean(prior_returns)\n",
    "\n",
    "momentum_0 = np.zeros(N)\n",
    "for i in range(N):\n",
    "    prior_returns_0 = np.zeros(L)\n",
    "    for l in range(L):\n",
    "        prior_returns_0[l] = 100*(prices[start-l-1,i]/prices[start-l-2,i]-1)\n",
    "    momentum_0[i] = np.mean(prior_returns_0)\n",
    "    \n",
    "np.savez(r\"C:\\Users\\zhubr\\OneDrive\\Desktop\\ECON 492\\data\\old-i\\momentum.npz\",data=momentum)\n",
    "\n",
    "## COMPUTE INSTRUMENT ###\n",
    "\n",
    "# get supply\n",
    "supply = np.zeros((T-start,N))\n",
    "for t in range(start,T):\n",
    "    for i in range(N):\n",
    "        supply[t-start,i] = mktcap[t,i]/prices[t,i]\n",
    "        \n",
    "np.savez(r\"C:\\Users\\zhubr\\OneDrive\\Desktop\\ECON 492\\data\\old-i\\supply.npz\",data=supply)\n",
    "\n",
    "# get powind\n",
    "\n",
    "coin_list = prices_df.columns[1:].values\n",
    "coin_list_pow = ['bitcoin','ethereum','dogecoin','litecoin','bitcoin-cash','ethereum-classic',\n",
    "                 'monero','zcash','bitcoin-cash-sv','kadena','ravencoin','siacoin','syscoin',\n",
    "                 'digibyte','nervos-network']\n",
    "\n",
    "powind = np.zeros(N)\n",
    "for i in range(N):\n",
    "    if coin_list[i] in coin_list_pow:\n",
    "        powind[i] = 1\n",
    "np.savez(r\"C:\\Users\\zhubr\\OneDrive\\Desktop\\ECON 492\\data\\old-i\\powind.npz\",data=powind)\n",
    "\n",
    "# save rfrate\n",
    "\n",
    "np.savez(r\"C:\\Users\\zhubr\\OneDrive\\Desktop\\ECON 492\\data\\old-i\\rfrate.npz\",data=rfrate[start:])\n",
    "        \n",
    "### UPDATE DIMENSIONS ###\n",
    "T = returns.shape[0]\n",
    "N = returns.shape[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "### COMPUTE QUANTILE PORTFOLIOS RETURNS ###\n",
    "\n",
    "def get_quantile_portfolio_returns(H,Q,returns,size,size_0,factor,factor_0,flip=0,verbose=0):\n",
    "    \n",
    "    # read dimensions\n",
    "    T = returns.shape[0]\n",
    "    N = returns.shape[1]\n",
    "    \n",
    "    # set parameters\n",
    "    Q_break = int(N/Q)\n",
    "    Q_portfolio_returns = np.zeros((T,Q))\n",
    "    \n",
    "    # initial objects\n",
    "    T_hold = 0\n",
    "    sorted_factor_idx = np.zeros(N)\n",
    "    if flip == 0:\n",
    "        sorted_factor_idx = np.flip(np.argsort(factor_0))\n",
    "    else:\n",
    "        sorted_factor_idx = np.argsort(factor_0)\n",
    "        \n",
    "    # compute returns\n",
    "    for t in range(T):\n",
    "        for q in range(Q):\n",
    "            if T_hold == 0:\n",
    "                if q == (Q-1):\n",
    "                    Q_curr_idx = sorted_factor_idx[(q*Q_break):N]\n",
    "                    Q_curr_size = np.sum(size_0[Q_curr_idx])\n",
    "                    for i in range(len(Q_curr_idx)):\n",
    "                        Q_portfolio_returns[t,q] += returns[t,Q_curr_idx[i]]*(size_0[Q_curr_idx[i]]/Q_curr_size)\n",
    "                else:\n",
    "                    Q_curr_idx = sorted_factor_idx[(q*Q_break):((q+1)*Q_break)]\n",
    "                    Q_curr_size = np.sum(size_0[Q_curr_idx])\n",
    "                    for i in range(len(Q_curr_idx)):\n",
    "                        Q_portfolio_returns[t,q] += returns[t,Q_curr_idx[i]]*(size_0[Q_curr_idx[i]]/Q_curr_size)\n",
    "            else:\n",
    "                if q == (Q-1):\n",
    "                    Q_curr_idx = sorted_factor_idx[(q*Q_break):N]\n",
    "                    Q_curr_size = np.sum(size[T_hold,Q_curr_idx])\n",
    "                    for i in range(len(Q_curr_idx)):\n",
    "                        Q_portfolio_returns[t,q] += returns[t,Q_curr_idx[i]]*(size[T_hold,Q_curr_idx[i]]/Q_curr_size)\n",
    "                else:\n",
    "                    Q_curr_idx = sorted_factor_idx[(q*Q_break):((q+1)*Q_break)]\n",
    "                    Q_curr_size = np.sum(size[T_hold,Q_curr_idx])\n",
    "                    for i in range(len(Q_curr_idx)):\n",
    "                        Q_portfolio_returns[t,q] += returns[t,Q_curr_idx[i]]*(size[T_hold,Q_curr_idx[i]]/Q_curr_size)\n",
    "        if t%H == (H-1):\n",
    "            T_hold = t\n",
    "            if flip == 0:\n",
    "                sorted_factor_idx = np.flip(np.argsort(factor[t,:]))\n",
    "            else:\n",
    "                sorted_factor_idx = np.argsort(factor[t,:])\n",
    "                \n",
    "    if verbose >= 1:\n",
    "        print(np.mean(Q_portfolio_returns,axis=0))\n",
    "        if verbose >= 2:\n",
    "            print(st.ttest_rel(Q_portfolio_returns[:,(1-1)],Q_portfolio_returns[:,(Q-1)],alternative='greater'))\n",
    "    \n",
    "    return Q_portfolio_returns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.46794644075004377"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.mean(momentum_qpr[365:,0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "### COMPUTE SIZE-FACTOR PORTFOLIO RETURNS ###\n",
    "\n",
    "# for t in range(T):\n",
    "#     print(np.sum(np.flip(np.sort(size[t,:]))[:20])/np.sum(np.flip(np.sort(size[t,:]))))\n",
    "\n",
    "def get_size_factor_portfolio_returns(H,returns,size,size_0,factor,factor_0,verbose=0):\n",
    "    \n",
    "    # read dimensions\n",
    "    T = returns.shape[0]\n",
    "    N = returns.shape[1]\n",
    "\n",
    "    # set parameters\n",
    "    S_break = np.array([0,20,100])\n",
    "    F_break = np.array([0,30,70,100])\n",
    "    SF_portfolio_returns = np.zeros((T,2,3))\n",
    "\n",
    "    # initial objects\n",
    "    T_hold = 0\n",
    "    S_sorted_idx = np.flip(np.argsort(size_0))\n",
    "    F_sorted_idx = np.flip(np.argsort(factor_0))\n",
    "\n",
    "    # compute returns\n",
    "    for t in range(T):\n",
    "        for s in range(2):\n",
    "            for f in range(3):\n",
    "                S_curr_idx = S_sorted_idx[S_break[s]:S_break[s+1]]\n",
    "                F_curr_idx = F_sorted_idx[F_break[f]:F_break[f+1]]\n",
    "                SF_curr_idx = np.intersect1d(S_curr_idx,F_curr_idx)\n",
    "                if T_hold == 0:\n",
    "                    SF_curr_size = np.sum(size_0[SF_curr_idx])\n",
    "                    for i in range(len(SF_curr_idx)):\n",
    "                        SF_portfolio_returns[t,s,f] += returns[t,SF_curr_idx[i]]*(size_0[SF_curr_idx[i]]/SF_curr_size)\n",
    "                else:\n",
    "                    SF_curr_size = np.sum(size[T_hold,SF_curr_idx])\n",
    "                    for i in range(len(SF_curr_idx)):\n",
    "                        SF_portfolio_returns[t,s,f] += returns[t,SF_curr_idx[i]]*(size[T_hold,SF_curr_idx[i]]/SF_curr_size)\n",
    "        if t%H == (H-1):\n",
    "            T_hold = t\n",
    "            S_sorted_idx = np.flip(np.argsort(size[T_hold,:]))\n",
    "            F_sorted_idx = np.flip(np.argsort(factor[T_hold,:]))\n",
    "            \n",
    "    if verbose >= 1:\n",
    "        print(np.array([[np.mean(SF_portfolio_returns[:,0,0]),np.mean(SF_portfolio_returns[:,0,1]),np.mean(SF_portfolio_returns[:,0,2])],\n",
    "                        [np.mean(SF_portfolio_returns[:,1,0]),np.mean(SF_portfolio_returns[:,1,1]),np.mean(SF_portfolio_returns[:,1,2])]]))\n",
    "        if verbose >= 2:\n",
    "            print(\"1:\",st.ttest_rel(SF_portfolio_returns[:,0,0],SF_portfolio_returns[:,1,0],alternative='less'))\n",
    "            print(\"2:\",st.ttest_rel(SF_portfolio_returns[:,0,1],SF_portfolio_returns[:,1,1],alternative='less'))\n",
    "            print(\"3:\",st.ttest_rel(SF_portfolio_returns[:,0,2],SF_portfolio_returns[:,1,2],alternative='less'))\n",
    "            print(\"B:\",st.ttest_rel(SF_portfolio_returns[:,0,0],SF_portfolio_returns[:,0,2],alternative='greater'))\n",
    "            print(\"S:\",st.ttest_rel(SF_portfolio_returns[:,1,0],SF_portfolio_returns[:,1,2],alternative='greater'))\n",
    "            \n",
    "    return SF_portfolio_returns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "### COMPUTE FACTORS ###\n",
    "\n",
    "def get_market(r_f,returns,size,size_0):\n",
    "    r_MKT = -r_f\n",
    "    total_size_0 = np.sum(size_0)\n",
    "    for i in range(N):\n",
    "        r_MKT[0] += returns[0,i]*(size_0[i]/total_size_0)\n",
    "    for t in range(1,T):\n",
    "        total_size = np.sum(size[t,:])\n",
    "        for i in range(N):\n",
    "            r_MKT[t] += returns[t,i]*(size[t,i]/total_size)\n",
    "    return r_MKT\n",
    "\n",
    "def get_factor(H,r_f,returns,size,size_0,factor,factor_0,verbose=0):\n",
    "    SF_portfolio_returns = get_size_factor_portfolio_returns(H,returns,size,size_0,factor,factor_0,verbose)\n",
    "    r_B1 = SF_portfolio_returns[:,0,0]\n",
    "    r_B2 = SF_portfolio_returns[:,0,1]\n",
    "    r_B3 = SF_portfolio_returns[:,0,2]\n",
    "    r_S1 = SF_portfolio_returns[:,1,0]\n",
    "    r_S2 = SF_portfolio_returns[:,1,1]\n",
    "    r_S3 = SF_portfolio_returns[:,1,2]\n",
    "    r_SMB = -r_f\n",
    "    r_1M3 = -r_f\n",
    "    for t in range(T):\n",
    "        r_SMB[t] += ((r_S1[t]+r_S2[t]+r_S3[t])/3)-((r_B1[t]+r_B2[t]+r_B3[t])/3)\n",
    "        r_1M3[t] += ((r_B1[t]+r_S1[t])/2)-((r_B3[t]+r_S3[t])/2)\n",
    "    return r_SMB, r_1M3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1.18859584 0.84850247 0.69217609 0.68150765 0.48281357]\n",
      "Ttest_relResult(statistic=4.588825022940104, pvalue=2.9550062585051545e-06)\n",
      "[0.90473138 0.63600739 0.5493092  0.44984996 0.32878139]\n",
      "Ttest_relResult(statistic=2.459993116880661, pvalue=0.007149841789788734)\n",
      "[0.61469556 0.32430608 0.73414268 0.77471655 0.42219522]\n",
      "Ttest_relResult(statistic=1.0487578591027995, pvalue=0.14744924243344804)\n",
      "[[0.68983887 0.49447034 0.18466893]\n",
      " [0.81999903 0.66640631 0.71468489]]\n",
      "1: Ttest_relResult(statistic=-0.7095531090637937, pvalue=0.2391894039644924)\n",
      "2: Ttest_relResult(statistic=-1.3700170117228978, pvalue=0.08571026660549969)\n",
      "3: Ttest_relResult(statistic=-3.150414270757705, pvalue=0.0008740778451537784)\n",
      "B: Ttest_relResult(statistic=2.1013935756123368, pvalue=0.018103692558876897)\n",
      "S: Ttest_relResult(statistic=0.7136519996235604, pvalue=0.2379212869662432)\n"
     ]
    }
   ],
   "source": [
    "size_qpr = get_quantile_portfolio_returns(H,Q,returns,size,size_0,size,size_0,flip=1,verbose=2)\n",
    "momentum_qpr = get_quantile_portfolio_returns(H,Q,returns,size,size_0,momentum,momentum_0,verbose=2)\n",
    "value_qpr = get_quantile_portfolio_returns(H,Q,returns,size,size_0,value,value_0,verbose=2)\n",
    "\n",
    "r_MKT = get_market(r_f,returns,size,size_0)\n",
    "r_SMB, r_WML = get_factor(H,r_f,returns,size,size_0,momentum,momentum_0,verbose=2)\n",
    "\n",
    "r = np.zeros((T,N))\n",
    "for t in range(T):\n",
    "    r[t,:] = returns[t,:]-r_f[t]\n",
    "F = np.column_stack((r_MKT,r_SMB,r_WML))\n",
    "\n",
    "np.savez(r\"C:\\Users\\zhubr\\OneDrive\\Desktop\\ECON 492\\data\\old-i\\r.npz\",r=r)\n",
    "np.savez(r\"C:\\Users\\zhubr\\OneDrive\\Desktop\\ECON 492\\data\\old-i\\F.npz\",F=F)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Compare factor model with benchmark CAPM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average |α|: 0.32269160254366364\n",
      "Average R^2: 0.3771075115155573\n",
      "Average σ^2: 6.637511939281218\n"
     ]
    }
   ],
   "source": [
    "# fit CAPM\n",
    "α_CAPM = np.zeros(N)\n",
    "ρ_CAPM = np.zeros(N)\n",
    "σ_CAPM = np.zeros(N)\n",
    "for i in range(N):\n",
    "    y = r[:,i]\n",
    "    X = np.column_stack((np.ones(T),r_MKT))\n",
    "    mod = sm.OLS(y,X)\n",
    "    res = mod.fit()\n",
    "    α_CAPM[i] = np.abs(res.params[0])\n",
    "    ρ_CAPM[i] = res.rsquared_adj\n",
    "    σ_CAPM[i] = la.norm(y-mod.predict(res.params,X))/np.sqrt(T)\n",
    "\n",
    "# show average alpha and R2adj\n",
    "print(\"Average |α|:\",np.mean(α_CAPM))\n",
    "print(\"Average R^2:\",np.mean(ρ_CAPM))\n",
    "print(\"Average σ^2:\",np.mean(σ_CAPM))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average |α|: 0.29196907508632175\n",
      "Average R^2: 0.4109619010717526\n",
      "Average σ^2: 6.434323642920367\n"
     ]
    }
   ],
   "source": [
    "# fit factor model\n",
    "α_FM = np.zeros(N)\n",
    "ρ_FM = np.zeros(N)\n",
    "σ_FM = np.zeros(N)\n",
    "for i in range(N):\n",
    "    y = r[:,i]\n",
    "    X = np.column_stack((np.ones(T),r_MKT,r_SMB,r_WML))\n",
    "    mod = sm.OLS(y,X)\n",
    "    res = mod.fit()\n",
    "    α_FM[i] = np.abs(res.params[0])\n",
    "    ρ_FM[i] = res.rsquared_adj\n",
    "    σ_FM[i] = la.norm(y-mod.predict(res.params,X))/np.sqrt(T)\n",
    "\n",
    "# show average alpha and R2adj\n",
    "print(\"Average |α|:\",np.mean(α_FM))\n",
    "print(\"Average R^2:\",np.mean(ρ_FM))\n",
    "print(\"Average σ^2:\",np.mean(σ_FM))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ttest_relResult(statistic=2.8602173941539806, pvalue=0.002582080291672419)\n",
      "Ttest_relResult(statistic=-13.245040033598384, pvalue=6.0014815095439506e-24)\n",
      "Ttest_relResult(statistic=13.108212823942855, pvalue=2.318529297652082e-23)\n"
     ]
    }
   ],
   "source": [
    "print(st.ttest_rel(α_CAPM,α_FM,alternative='greater'))\n",
    "print(st.ttest_rel(ρ_CAPM,ρ_FM,alternative='less'))\n",
    "print(st.ttest_rel(σ_CAPM,σ_FM))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Summary statistics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.36659695044241963\n",
      "4.11502648108964\n",
      "0.10495659800470612\n",
      "1.551271030028106\n",
      "-6.146063788153283\n",
      "7.603922046849376\n"
     ]
    }
   ],
   "source": [
    "i = 0\n",
    "print(np.mean(r[:,i]))\n",
    "print(np.std(r[:,i]))\n",
    "print(st.skew(r[:,i]))\n",
    "print(st.kurtosis(r[:,i]))\n",
    "print(np.percentile(r[:,i],5))\n",
    "print(np.percentile(r[:,i],95))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.6680698997397091\n",
      "5.394957251017586\n",
      "-0.08100999822315703\n",
      "2.9631691644373195\n",
      "-7.502506872492214\n",
      "8.982019360189478\n"
     ]
    }
   ],
   "source": [
    "i = 1\n",
    "print(np.mean(r[:,i]))\n",
    "print(np.std(r[:,i]))\n",
    "print(st.skew(r[:,i]))\n",
    "print(st.kurtosis(r[:,i]))\n",
    "print(np.percentile(r[:,i],5))\n",
    "print(np.percentile(r[:,i],95))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.972988619722073\n",
      "20.151848959663553\n",
      "11.832996885301188\n",
      "187.43986819237395\n",
      "-10.386442832379657\n",
      "18.78044277607217\n"
     ]
    }
   ],
   "source": [
    "i = 7\n",
    "print(np.mean(r[:,i]))\n",
    "print(np.std(r[:,i]))\n",
    "print(st.skew(r[:,i]))\n",
    "print(st.kurtosis(r[:,i]))\n",
    "print(np.percentile(r[:,i],5))\n",
    "print(np.percentile(r[:,i],95))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
